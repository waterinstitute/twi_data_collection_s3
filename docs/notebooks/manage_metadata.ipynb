{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the proposed metadata approach\n",
    "\n",
    "We want to have metadata expressed in text files in s3 alongside the actual datasets. In the proposed schema the yaml files will contain all the necessary information about the datasources, including its geographical region. \n",
    "https://gist.github.com/cronosnull/a179f1bba556e724ce58cb50d7f02b86\n",
    "There are two variants of metadata-external.yml, one with independent documents for each dataset and other with a list of datasets (so you can use YAML anchoring to reuse blocks from previous documents in the same file). \n",
    "\n",
    "We can use this script to find the metadata files, map it into a dataframe and finaly convert it into features in the arcgis online instance (so AGOL will be the portal to find the datasets based on geographical or metadata based queries). \n",
    "\n",
    "### sample yaml file\n",
    "\n",
    "```yaml\n",
    "--- \n",
    " \n",
    "global_attributes:\n",
    "  title: CEOS Data Cube Landsat Surface Reflectance\n",
    "  summary: Landsat 8 Operational Land Imager ARD prepared by NASA on behalf of CEOS.\n",
    "  source: LaSRC surface reflectance product prepared using USGS Collection 1 data.\n",
    "  institution: CEOS\n",
    "  instrument: OLI_TIRS\n",
    "  cdm_data_type: Grid\n",
    "  keywords: AU/GA,NASA/GSFC/SED/ESD/LANDSAT,REFLECTANCE,ETM+,TM,OLI,EARTH SCIENCE\n",
    "  keywords_vocabulary: GCMD\n",
    "  platform: LANDSAT_8\n",
    "  processing_level: L2\n",
    "  product_version: '2.0.0'\n",
    "  product_suite: USGS Landsat Collection 1\n",
    "  project: CEOS\n",
    "  coverage_content_type: physicalMeasurement\n",
    "  references: http://dx.doi.org/10.3334/ORNLDAAC/1146\n",
    "  license: https://creativecommons.org/licenses/by/4.0/\n",
    "  naming_authority: gov.usgs\n",
    "  acknowledgment: Landsat data is provided by the United States Geological Survey (USGS).\n",
    "  topic: Imagery and base maps\n",
    "  start_date: 20210106\n",
    "  end_date: 20210106\n",
    "  creation_date: 20210111\n",
    "  published_date: 20210112\n",
    "  crs: \"EPSG:4326\"\n",
    "bounds_wkt: MultiPolygon (((-99.01244262644466687 29.68847714169181984, -99.01260000000000616 29.68850000000000122, -99.00405966608576591 29.72230390603985484, -98.99370927257297126 29.76327229595236545, -98.64920488997823611 31.12687164657319272, -98.6396011275921154 31.16488475994666985, -98.63030000000000541 31.20169999999999888, -98.63011103786386968 31.20167254176426752, -96.72060000000000457 30.92419999999999902, -96.72841089687504734 30.89548010871237338, -97.12329597297051009 29.44352694148999205, -97.13100000000000023 29.41519999999999868, -99.01244262644466687 29.68847714169181984)))\n",
    "index_location: s3://landsat-pds/c1/L8/027/039/LO08_L1TP_027039_20201106_20201111_01_T1/index.html\n",
    "metadata_contacts:\n",
    "  name: Christian Ariza\n",
    "  email: carizaporras@NOTSPAMTWI.org\n",
    "  role: user\n",
    "measurements:\n",
    "    - name: coastal_aerosol\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band1'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 0.43-0.45 microns (Coastal Aerosol)\"\n",
    "          alias: \"band_1\"\n",
    "    - name: blue\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band2'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 0.45-0.51 microns (Blue)\"\n",
    "          alias: \"band_2\"\n",
    "    - name: green\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band3'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 0.53-0.59 microns (Green)\"\n",
    "          alias: \"band_4\"\n",
    "    - name: red\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band4'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 0.64-0.67 microns (Red)\"\n",
    "          alias: \"band_4\"\n",
    "    - name: nir\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band5'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 0.85-0.88 microns (Near Infrared)\"\n",
    "          alias: \"band_5\"\n",
    "    - name: swir1\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band6'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 1.57-1.65 microns (Short-wave Infrared)\"\n",
    "          alias: \"band_6\"\n",
    "    - name: swir2\n",
    "      dtype: int16\n",
    "      nodata: -9999\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_band7'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Surface Reflectance 2.11-2.29 microns (Short-wave Infrared)\"\n",
    "          alias: \"band_7\"\n",
    "    - name: 'pixel_qa'\n",
    "      dtype: int32\n",
    "      nodata: 1\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'pixel_qa'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Pixel Quality Attributes Bit Index\"\n",
    "          alias: [pixel_qa]\n",
    "    - name: 'aerosol_qa'\n",
    "      dtype: uint8\n",
    "      nodata: 0\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sr_aerosol'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Aerosol Quality Attributes Bit Index\"\n",
    "          alias: [sr_aerosol_qa, sr_aerosol]\n",
    "    - name: 'radsat_qa'\n",
    "      dtype: int32\n",
    "      nodata: 1\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'radsat_qa'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Radiometric Saturation Quality Attributes Bit Index\"\n",
    "          alias: [radsat_qa]\n",
    "    - name: 'solar_azimuth'\n",
    "      dtype: int16\n",
    "      nodata: -32768\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'solar_azimuth_band4'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Solar Azimuth Angle for Band 4\"\n",
    "          alias: [solar_azimuth_band4]\n",
    "    - name: 'solar_zenith'\n",
    "      dtype: int16\n",
    "      nodata: -32768\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'solar_zenith_band4'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Solar Zenith Angle for Band 4\"\n",
    "          alias: [solar_zenith_band4]\n",
    "    - name: 'sensor_azimuth'\n",
    "      dtype: int16\n",
    "      nodata: -32768\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sensor_azimuth_band4'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Sensor Azimuth Angle for Band 4\"\n",
    "          alias: [sensor_azimuth_band4]\n",
    "    - name: 'sensor_zenith'\n",
    "      dtype: int16\n",
    "      nodata: -32768\n",
    "      resampling_method: nearest\n",
    "      src_varname: 'sensor_zenith_band4'\n",
    "      zlib: True\n",
    "      attrs:\n",
    "          long_name: \"Sensor Zenith Angle for Band 4\"\n",
    "          alias: [sensor_zenith_band4]\n",
    "lineage:\n",
    "  description: \"\"\n",
    "  source: \"<URI for the source file>\"\n",
    "  process: \"LaSRC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS\n",
    "project = \"TEST\" #Either GLO, LWI, OR TEST\n",
    "process_all = True\n",
    "buckets = {\"GLO\": [\"glo-data\"], \"LWI\":[\"lwi-common\", *[f\"lwi-region{x}\" for x in range(1,8)]], \"TEST\": [\"test-bucket\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import yaml\n",
    "import datetime\n",
    "import boto3  # aws client api\n",
    "from botocore.client import Config\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "from hashlib import sha3_256\n",
    "\n",
    "# to work with maps:\n",
    "from shapely import wkt, ops\n",
    "import geopandas\n",
    "import contextily as ctx\n",
    "\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "boto3.setup_default_session(profile_name=project)\n",
    "hucs_gdf = geopandas.read_file(r\"./glo_eastregion_huc08.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huc2geometry(x):\n",
    "    \"\"\"\n",
    "    If the code is huc_8 returns the geometry from the hucs_gdf.\n",
    "    If it is a huc 4 or 6, it returns the union of the geometries of the matching rows.\n",
    "    params:\n",
    "        x: a string or an number representing the huc.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    huc_s = str(int(x))\n",
    "    huc_type = len(huc_s)\n",
    "    if huc_type == 8:\n",
    "        return hucs_gdf.loc[hucs_gdf.HUC_8 == huc_s].geometry.values[0]\n",
    "    else:\n",
    "        values = hucs_gdf.loc[hucs_gdf[f\"HUC_{huc_type}\"] == huc_s].geometry.values\n",
    "        return ops.unary_union(values)\n",
    "\n",
    "\n",
    "def hash_doc(doc):\n",
    "    return sha3_256(json.dumps(doc, default=str).encode(\"utf-8\")).hexdigest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the metadata from the s3 buckets\n",
    "\n",
    "We should query the buckets for the metadata.yaml or metadata-external.yaml files (or other patterns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_buckets(project, process_all=True):\n",
    "    \"\"\"\n",
    "    get the data from the buckets of the project\n",
    "    \"\"\"\n",
    "    kargs = {}\n",
    "    if project == \"TEST\":\n",
    "        kargs[\"endpoint_url\"] = \"http://localhost:9000\"\n",
    "        kargs[\"config\"] = Config(signature_version=\"s3v4\")\n",
    "    already_seen = []\n",
    "    if not process_all:\n",
    "        hash_files = glob.glob(\"processed_hash_*\")\n",
    "        if hash_files:\n",
    "            _pdf = pd.concat(map(pd.read_csv, hash_files))\n",
    "            already_seen = _pdf.metadata_hash.to_list()\n",
    "    s3 = boto3.resource(\"s3\", **kargs)\n",
    "    p_buckets = buckets[project]\n",
    "    for b in p_buckets:\n",
    "        s3_bucket = s3.Bucket(b)\n",
    "        metadata_files = [\n",
    "            f\"{x.key}\"\n",
    "            for x in s3_bucket.objects.all()\n",
    "            if any(\n",
    "                map(\n",
    "                    x.key.__contains__,\n",
    "                    [\n",
    "                        \"metadata.yml\",\n",
    "                        \"metadata-external.yml\",\n",
    "                        \"metadata.yaml\",\n",
    "                        \"metadata-external.yaml\",\n",
    "                    ],\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        metadata_list = []\n",
    "        for mfile in metadata_files:\n",
    "            obj = s3_bucket.Object(mfile).get()\n",
    "            content = obj[\"Body\"].read()\n",
    "            metadata_gen = yaml.load_all(content, Loader=Loader)\n",
    "            folder = f\"s3://{s3_bucket.name}/{mfile[:mfile.rfind('/')+1]}\"\n",
    "            try:\n",
    "                for document in metadata_gen:\n",
    "                    if isinstance(document, list):\n",
    "                        for d in document:\n",
    "                            d[\"metadata_hash\"] = hash_doc(d)\n",
    "                            d[\"metadata_folder\"] = folder\n",
    "                        metadata_list.extend(document)\n",
    "                    else:\n",
    "                        document[\"metadata_hash\"] = hash_doc(document)\n",
    "                        document[\"metadata_folder\"] = folder\n",
    "                        metadata_list.append(document)\n",
    "            except yaml.error.YAMLError:\n",
    "                print(\n",
    "                    f\"Invalid syntax on s3://{s3_bucket.name}{mfile}, the dataset(s) defined on it will be ignored\"\n",
    "                )\n",
    "                continue\n",
    "        metadata_df = pd.json_normalize(metadata_list)\n",
    "        metadata_df.drop(\n",
    "            metadata_df[metadata_df.metadata_hash.isin(already_seen)].index,\n",
    "            inplace=True,\n",
    "        )\n",
    "        # If all the datasets has been already seen, exit.\n",
    "        return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_geodataframe(project, process_all=True):\n",
    "    \"\"\"\n",
    "    Generate a geodataframe for all the buckets of a given project\n",
    "    \"\"\"\n",
    "    metadata_df = get_metadata_from_buckets(project, process_all)\n",
    "    metadata_df[\"limits\"] = metadata_df.bounds_wkt.apply(\n",
    "        lambda x: wkt.loads(x) if pd.notnull(x) else None\n",
    "    )\n",
    "    if \"bounds_huc\" in metadata_df:\n",
    "        metadata_df[\"limits\"] = metadata_df.apply(\n",
    "            lambda row: huc2geometry(row.bounds_huc)\n",
    "            if pd.notnull(row.bounds_huc)\n",
    "            else row.limits,\n",
    "            axis=1,\n",
    "        )\n",
    "    metadata_df.index_location = metadata_df.apply(\n",
    "        lambda x: x.index_location\n",
    "        if bool(urlparse(x.index_location).netloc)\n",
    "        else f\"{x.metadata_folder}{x.index_location}\",\n",
    "        axis=1,\n",
    "    )\n",
    "    metadata_df[\"name\"] = metadata_df[\"global_attributes.title\"]\n",
    "    metadata_gdf = geopandas.GeoDataFrame(metadata_df, geometry=metadata_df.limits)\n",
    "    metadata_gdf = metadata_gdf.drop(\n",
    "        columns=[\"limits\", \"bounds_wkt\"], errors=\"ignore\"\n",
    "    )  # ignore if they don't exists\n",
    "    metadata = metadata_gdf.set_crs(crs=\"EPSG:4326\")\n",
    "    if \"measurements\" in metadata_gdf:\n",
    "        metadata_gdf[\"measurements\"] = metadata_gdf[\"measurements\"].apply(\n",
    "            lambda x: json.dumps(x, default=str) if x is not None else None\n",
    "        )\n",
    "    for col in metadata_gdf:\n",
    "        metadata_gdf[col] = metadata_gdf[col].apply(\n",
    "            lambda x: x if not isinstance(x, list) else json.dumps(x, default=str)\n",
    "        )\n",
    "    return metadata_gdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main process:\n",
    "metadata_gdf = generate_geodataframe(project, process_all)\n",
    "if not metadata_gdf.empty:\n",
    "    # Save the gdf to file\n",
    "    metadata_gdf.to_file(\"datasources.json\", driver=\"GeoJSON\")\n",
    "    # Create the checkpoint file (list of hashes)\n",
    "    metadata_gdf[[\"metadata_hash\"]].to_csv(\n",
    "        f\"processed_hash_{datetime.datetime.utcnow().timestamp()}\", index=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the datasets: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the rows should have the same projection, so this change should be either enforced by policy or made beforehand\n",
    "tmp = metadata_gdf.set_crs(crs=\"EPSG:4326\") \n",
    "#to match with the ctx map, we should use web mercator projection:\n",
    "ax = tmp.to_crs(epsg=3857).plot( figsize=(100, 100), alpha=0.5) \n",
    "ctx.add_basemap(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metadata_gdf.measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARCGIS TEST\n",
    "Publish the data to arcgis online (it requires a valid user with publish permissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis import GeoAccessor, GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcgis_ga = GeoAccessor.from_geodataframe(metadata_gdf, column_name=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gis = GIS(\"https://twiotg.maps.arcgis.com\", \"<username>\", \"<password>\")\n",
    "arcgis_ga.spatial.to_featurelayer(f'datasets_{project}',tags=[project, \"datasets\", \"metadata\"], folder=project, gis=gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DataTests]",
   "language": "python",
   "name": "conda-env-DataTests-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
